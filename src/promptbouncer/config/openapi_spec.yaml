openapi: 3.0.3
info:
  title: Prompt Bouncer REST API
  description: Get a threat analysis for an incoming LLM Prompt.
  version: 1.2.0
externalDocs:
  description: Prompt Bouncer Documentation
  url: http://docs.promptbouncer.com/
paths:
  /v1/threat-assessment:
    post:
      summary: Perform a threat assessment
      description: Accepts a threat assessment request and returns a threat assessment response.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ThreatAssessmentRequest'
      responses:
        '200':
          description: A successful threat assessment response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreatAssessment'
        '400':
          description: Invalid request.
          content:
            application/json:
              schema:
                type: object
                properties:
                  detail:
                    type: string
                    example: "Invalid input data."
components:
  schemas:
    ThreatAssessmentRequest:
      type: object
      properties:
        prompt:
          type: string
          example: "What is a cat?"
      required:
        - prompt
    ThreatAssessment:
      type: object
      properties:
        threats:
          type: array
          items:
            $ref: '#/components/schemas/Threat'
        assessment_score:
          type: number
          format: float
          example: 6.7
        assessment_description:
          type: string
          example: "Elevated threat level. Attention is required."
        assessment_confidence:
          type: number
          format: float
          example: 6.7
        recommendation:
           type: string
           description: A recommendation from the bouncer.
           enum:
             - INSPECT_THREATS
             - STOP_NO_ENTRY
             - OK_LET_THROUGH
    ThreatScanner:
      type: object
      properties:
        name:
          type: string
          example: "PromptHijackScanner"
    Threat:
      type: object
      properties:
        threat_scan:
          type: string
          example: "PromptHijackScanner"
        threat_scan_description:
          type: string
          example: "A scan to check prompt hijacking."
        threat_level:
          type: string
          example: "Critical"
        threat_details:
          type: string
          example: "There seems to an attempt to hijack the prompt."
        confidence:
          type: float
          example: 0.8
        time_taken_seconds:
          type: float
          example: 10.2